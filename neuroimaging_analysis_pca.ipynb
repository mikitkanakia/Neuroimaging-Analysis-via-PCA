{"cells":[{"cell_type":"markdown","source":["# **Principal Component Analysis Assignment**\n#### This project delves into exploratory analysis of neuroscience data, specifically using principal component analysis (PCA) and feature-based aggregation. We will use a dataset of light-sheet imaging recorded by the [Ahrens Lab](http://www.janelia.org/lab/ahrens-lab) at Janelia Research Campus, and hosted on the CodeNeuro [data repository](http://datasets.codeneuro.org).\n#### Our dataset is generated by studying the movement of a larval [zebrafish](http://en.wikipedia.org/wiki/Zebrafish), an animal that is especially useful in neuroscience because it is transparent, making it possible to record activity over its entire brain using a technique called [light-sheet microscopy](http://en.wikipedia.org/wiki/Light_sheet_fluorescence_microscopy).   Specifically, we'll work with time-varying images containing patterns of the zebrafish's neural activity as it is presented with a moving visual pattern.   Different stimuli induce different patterns across the brain, and we can use exploratory analyses to identify these patterns."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["### **Part 1: Work through the steps of PCA on a sample dataset**"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["#### **Visualization 1: Two-dimensional Gaussians**\n#### Principal Component Analysis, or PCA, is a strategy for dimensionality reduction. To better understand PCA, we'll work with synthetic data generated by sampling from the [two-dimensional Gaussian distribution](http://en.wikipedia.org/wiki/Multivariate_normal_distribution).  This distribution takes as input the mean and variance of each dimension, as well as the covariance between the two dimensions.\n \n#### In our visualizations below, we will specify the mean of each dimension to be 50 and the variance along each dimension to be 1.  We will explore two different values for the covariance: 0 and 0.9. When the covariance is zero, the two dimensions are uncorrelated, and hence the data looks spherical.  In contrast, when the covariance is 0.9, the two dimensions are strongly (positively) correlated and thus the data is non-spherical.  As we'll see in Parts 1 and 2, the non-spherical data is amenable to dimensionality reduction via PCA, while the spherical data is not."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport numpy as np\n\ndef preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n                gridWidth=1.0):\n    \"\"\"Template for generating the plot layout.\"\"\"\n    plt.close()\n    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n        axis.set_ticks_position('none')\n        axis.set_ticks(ticks)\n        axis.label.set_color('#999999')\n        if hideLabels: axis.set_ticklabels([])\n    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n    return fig, ax\n\ndef create2DGaussian(mn, sigma, cov, n):\n    \"\"\"Randomly sample points from a two-dimensional Gaussian distribution\"\"\"\n    np.random.seed(142)\n    return np.random.multivariate_normal(np.array([mn, mn]), np.array([[sigma, cov], [cov, sigma]]), n)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":["dataRandom = create2DGaussian(mn=50, sigma=1, cov=0, n=100)\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(46, 55, 2), np.arange(46, 55, 2))\nax.set_xlabel(r'Simulated $x_1$ values'), ax.set_ylabel(r'Simulated $x_2$ values')\nax.set_xlim(45, 54.5), ax.set_ylim(45, 54.5)\nplt.scatter(dataRandom[:,0], dataRandom[:,1], s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":["dataCorrelated = create2DGaussian(mn=50, sigma=1, cov=.9, n=100)\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(46, 55, 2), np.arange(46, 55, 2))\nax.set_xlabel(r'Simulated $x_1$ values'), ax.set_ylabel(r'Simulated $x_2$ values')\nax.set_xlim(45.5, 54.5), ax.set_ylim(45.5, 54.5)\nplt.scatter(dataCorrelated[:,0], dataCorrelated[:,1], s=14**2, c='#d6ebf2',\n            edgecolors='#8cbfd0', alpha=0.75)\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["#### **(1a) Interpreting PCA**\n#### PCA can be interpreted as identifying the \"directions\" along which the data vary the most. In the first step of PCA, we must first center our data.  Working with our correlated dataset, first compute the mean of each feature (column) in the dataset.  Then for each observation, modify the features by subtracting their corresponding mean, to create a zero mean dataset.\n#### Note that `correlatedData` is an RDD of NumPy arrays.  This allows us to perform certain operations more succinctly."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["correlatedData = sc.parallelize(dataCorrelated)\n\nmeanCorrelated = correlatedData.mean()\ncorrelatedDataZeroMean = correlatedData.map(lambda x: x - meanCorrelated )\n\nprint meanCorrelated\nprint correlatedData.take(1)\nprint correlatedDataZeroMean.take(1)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["#### **(1b) Sample covariance matrix**\n#### We are now ready to compute the sample covariance matrix. If we define $\\scriptsize \\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ as the zero mean data matrix, then the sample covariance matrix is defined as: $$ \\mathbf{C}_{\\mathbf X} = \\frac{1}{n} \\mathbf{X}^\\top \\mathbf{X} \\,.$$  To compute this matrix, compute the outer product of each data point, add together these outer products, and divide by the number of data points. The data are two dimensional, so the resulting covariance matrix should be a 2x2 matrix."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["# Compute the covariance matrix using outer products and correlatedDataZeroMean\ncorrelatedCov = correlatedDataZeroMean.map(lambda x: np.outer(np.transpose(x),x)).sum()/correlatedDataZeroMean.count()\nprint correlatedCov"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["#### **(1c) Covariance Function**"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def estimateCovariance(data):\n    \"\"\"Compute the covariance matrix for a given rdd.\n\n    Note:\n        The multi-dimensional covariance array should be calculated using outer products.  Don't\n        forget to normalize the data by first subtracting the mean.\n\n    Args:\n        data (RDD of np.ndarray):  An `RDD` consisting of NumPy arrays.\n\n    Returns:\n        np.ndarray: A multi-dimensional array where the number of rows and columns both equal the\n            length of the arrays in the input `RDD`.\n    \"\"\"\n    data_Mean = data.mean()\n    data_ZeroMean = data.map(lambda x: x - data_Mean)\n    return data_ZeroMean.map(lambda x: np.outer(np.transpose(x),x)).sum()/data_ZeroMean.count()\n    \n\ncorrelatedCovAuto= estimateCovariance(correlatedData)\nprint correlatedCovAuto"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["#### **(1d) Eigendecomposition**\n#### Now that we've computed the sample covariance matrix, we can use it to find directions of maximal variance in the data.  Specifically, we can perform an eigendecomposition of this matrix to find its eigenvalues and eigenvectors.  The $\\scriptsize d $ eigenvectors of the covariance matrix give us the directions of maximal variance, and are often called the \"principal components.\"  The associated eigenvalues are the variances in these directions.  In particular, the eigenvector corresponding to the largest eigenvalue is the direction of maximal variance (this is sometimes called the \"top\" eigenvector). Eigendecomposition of a $\\scriptsize d \\times d $ covariance matrix has a (roughly) cubic runtime complexity with respect to $\\scriptsize d $.  Whenever $\\scriptsize d $ is relatively small (e.g., less than a few thousand) we can quickly perform this eigendecomposition locally."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["from numpy.linalg import eigh\n\n# Calculate the eigenvalues and eigenvectors from correlatedCovAuto\neigVals, eigVecs = np.linalg.eigh(correlatedCovAuto)\nprint 'eigenvalues: {0}'.format(eigVals)\nprint '\\neigenvectors: \\n{0}'.format(eigVecs)\n\n# Use np.argsort to find the top eigenvector based on the largest eigenvalue\ninds = np.argsort(eigVals)\ntopComponent = eigVecs[:,inds.tolist().index(len(eigVals)-1)]\nprint '\\ntop principal component: {0}'.format(topComponent)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["#### **(1e) PCA scores**\n#### We just computed the top principal component for a 2-dimensional non-spherical dataset.  Now let's use this principal component to derive a one-dimensional representation for the original data. To compute these compact representations, which are sometimes called PCA \"scores\", calculate the dot product between each data point in the raw data and the top principal component."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["# Use the topComponent and the data from correlatedData to generate PCA scores\ncorrelatedDataScores = correlatedData.map(lambda x: np.dot(x,topComponent))\nprint 'one-dimensional data (first three):\\n{0}'.format(np.asarray(correlatedDataScores.take(3)))"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["### **Part 2: Write a PCA function and evaluate PCA on sample datasets**"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["#### **(2a) PCA function**"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def pca(data, k=2):\n    \"\"\"Computes the top `k` principal components, corresponding scores, and all eigenvalues.\n\n    Note:\n        All eigenvalues should be returned in sorted order (largest to smallest). `eigh` returns\n        each eigenvectors as a column.  This function should also return eigenvectors as columns.\n\n    Args:\n        data (RDD of np.ndarray): An `RDD` consisting of NumPy arrays.\n        k (int): The number of principal components to return.\n\n    Returns:\n        tuple of (np.ndarray, RDD of np.ndarray, np.ndarray): A tuple of (eigenvectors, `RDD` of\n            scores, eigenvalues).  Eigenvectors is a multi-dimensional array where the number of\n            rows equals the length of the arrays in the input `RDD` and the number of columns equals\n            `k`.  The `RDD` of scores has the same number of rows as `data` and consists of arrays\n            of length `k`.  Eigenvalues is an array of length d (the number of features).\n    \"\"\"\n    \n    \n    correlatedCovAuto= estimateCovariance(data)\n    eigVals, eigVecs = np.linalg.eigh(correlatedCovAuto)\n    \n    final_eigVals = eigVals[::-1]\n  \n    inds1 = np.argsort(eigVals)[::-1]\n    \n    final_eigVecs1 = eigVecs[:,inds1]\n    final_eigVecs = final_eigVecs1[:,0:k]\n    \n    final_correlatedDataScores = data.map(lambda x: np.dot(x,final_eigVecs))\n    \n    # Return the `k` principal components, `k` scores, and all eigenvalues\n    return (final_eigVecs,final_correlatedDataScores,final_eigVals)\n\n    \n# Run pca on correlatedData with k = 2\ntopComponentsCorrelated, correlatedDataScoresAuto, eigenvaluesCorrelated = pca(correlatedData, 2)\n\n# Note that the 1st principal component is in the first column\nprint 'topComponentsCorrelated: \\n{0}'.format(topComponentsCorrelated)\nprint ('\\ncorrelatedDataScoresAuto (first three): \\n{0}'\n       .format('\\n'.join(map(str, correlatedDataScoresAuto.take(3)))))\nprint '\\neigenvaluesCorrelated: \\n{0}'.format(eigenvaluesCorrelated)\n\n# Create a higher dimensional test set\npcaTestData = sc.parallelize([np.arange(x, x + 4) for x in np.arange(0, 20, 4)])\ncomponentsTest, testScores, eigenvaluesTest = pca(pcaTestData, 3)\n\nprint '\\npcaTestData: \\n{0}'.format(np.array(pcaTestData.collect()))\nprint '\\ncomponentsTest: \\n{0}'.format(componentsTest)\nprint ('\\ntestScores (first three): \\n{0}'\n       .format('\\n'.join(map(str, testScores.take(3)))))\nprint '\\neigenvaluesTest: \\n{0}'.format(eigenvaluesTest)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["#### **(2b) PCA on `dataRandom`**\n#### Next, use the PCA function we just developed to find the top two principal components of the spherical `dataRandom` we created in Visualization 1."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["randomData = sc.parallelize(dataRandom)\n\n# Use pca on randomData\ntopComponentsRandom, randomDataScoresAuto, eigenvaluesRandom = pca(randomData, 2)\n\nprint 'topComponentsRandom: \\n{0}'.format(topComponentsRandom)\nprint ('\\nrandomDataScoresAuto (first three): \\n{0}'\n       .format('\\n'.join(map(str, randomDataScoresAuto.take(3)))))\nprint '\\neigenvaluesRandom: \\n{0}'.format(eigenvaluesRandom)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["#### **Visualization 2: PCA projection**\n#### Plot the original data and the 1-dimensional reconstruction using the top principal component to see how the PCA solution looks.  The original data is plotted as before; however, the 1-dimensional reconstruction (projection) is plotted in green on top of the original data and the vectors (lines) representing the two principal components are shown as dotted lines."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def projectPointsAndGetLines(data, components, xRange):\n    \"\"\"Project original data onto first component and get line details for top two components.\"\"\"\n    topComponent= components[:, 0]\n    slope1, slope2 = components[1, :2] / components[0, :2]\n\n    means = data.mean()[:2]\n    demeaned = data.map(lambda v: v - means)\n    projected = demeaned.map(lambda v: (v.dot(topComponent) /\n                                        topComponent.dot(topComponent)) * topComponent)\n    remeaned = projected.map(lambda v: v + means)\n    x1,x2 = zip(*remeaned.collect())\n\n    lineStartP1X1, lineStartP1X2 = means - np.asarray([xRange, xRange * slope1])\n    lineEndP1X1, lineEndP1X2 = means + np.asarray([xRange, xRange * slope1])\n    lineStartP2X1, lineStartP2X2 = means - np.asarray([xRange, xRange * slope2])\n    lineEndP2X1, lineEndP2X2 = means + np.asarray([xRange, xRange * slope2])\n\n    return ((x1, x2), ([lineStartP1X1, lineEndP1X1], [lineStartP1X2, lineEndP1X2]),\n            ([lineStartP2X1, lineEndP2X1], [lineStartP2X2, lineEndP2X2]))"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":["((x1, x2), (line1X1, line1X2), (line2X1, line2X2)) = \\\n    projectPointsAndGetLines(correlatedData, topComponentsCorrelated, 5)\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(46, 55, 2), np.arange(46, 55, 2), figsize=(7, 7))\nax.set_xlabel(r'Simulated $x_1$ values'), ax.set_ylabel(r'Simulated $x_2$ values')\nax.set_xlim(45.5, 54.5), ax.set_ylim(45.5, 54.5)\nplt.plot(line1X1, line1X2, linewidth=3.0, c='#8cbfd0', linestyle='--')\nplt.plot(line2X1, line2X2, linewidth=3.0, c='#d6ebf2', linestyle='--')\nplt.scatter(dataCorrelated[:,0], dataCorrelated[:,1], s=14**2, c='#d6ebf2',\n            edgecolors='#8cbfd0', alpha=0.75)\nplt.scatter(x1, x2, s=14**2, c='#62c162', alpha=.75)\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":["((x1, x2), (line1X1, line1X2), (line2X1, line2X2)) = \\\n    projectPointsAndGetLines(randomData, topComponentsRandom, 5)\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(46, 55, 2), np.arange(46, 55, 2), figsize=(7, 7))\nax.set_xlabel(r'Simulated $x_1$ values'), ax.set_ylabel(r'Simulated $x_2$ values')\nax.set_xlim(45.5, 54.5), ax.set_ylim(45.5, 54.5)\nplt.plot(line1X1, line1X2, linewidth=3.0, c='#8cbfd0', linestyle='--')\nplt.plot(line2X1, line2X2, linewidth=3.0, c='#d6ebf2', linestyle='--')\nplt.scatter(dataRandom[:,0], dataRandom[:,1], s=14**2, c='#d6ebf2',\n            edgecolors='#8cbfd0', alpha=0.75)\nplt.scatter(x1, x2, s=14**2, c='#62c162', alpha=.75)\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["#### **Visualization 3: Three-dimensional data**\n#### So far we have worked with two-dimensional data. Now let's generate three-dimensional data with highly correlated features. As in Visualization 1, we'll create samples from a multivariate Gaussian distribution, which in three dimensions requires us to specify three means, three variances, and three covariances.\n \n#### In the 3D graphs below, we have included the 2D plane that corresponds to the top two principal components, i.e. the plane with the smallest euclidean distance between the points and itself. Notice that the data points, despite living in three-dimensions, are found near a two-dimensional plane: the left graph shows how most points are close to the plane when it is viewed from its side, while the right graph shows that the plane covers most of the variance in the data.  Note that darker blues correspond to points with higher values for the third dimension."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["from mpl_toolkits.mplot3d import Axes3D\n\nm = 100\nmu = np.array([50, 50, 50])\nr1_2 = 0.9\nr1_3 = 0.7\nr2_3 = 0.1\nsigma1 = 5\nsigma2 = 20\nsigma3 = 20\nc = np.array([[sigma1 ** 2, r1_2 * sigma1 * sigma2, r1_3 * sigma1 * sigma3],\n             [r1_2 * sigma1 * sigma2, sigma2 ** 2, r2_3 * sigma2 * sigma3],\n             [r1_3 * sigma1 * sigma3, r2_3 * sigma2 * sigma3, sigma3 ** 2]])\nnp.random.seed(142)\ndataThreeD = np.random.multivariate_normal(mu, c, m)\n\nfrom matplotlib.colors import ListedColormap, Normalize\nfrom matplotlib.cm import get_cmap\nnorm = Normalize()\ncmap = get_cmap(\"Blues\")\nclrs = cmap(np.array(norm(dataThreeD[:,2])))[:,0:3]\n\nfig = plt.figure(figsize=(11, 6))\nax = fig.add_subplot(121, projection='3d')\nax.azim=-100\nax.scatter(dataThreeD[:,0], dataThreeD[:,1], dataThreeD[:,2], c=clrs, s=14**2)\n\nxx, yy = np.meshgrid(np.arange(-15, 10, 1), np.arange(-50, 30, 1))\nnormal = np.array([0.96981815, -0.188338, -0.15485978])\nz = (-normal[0] * xx - normal[1] * yy) * 1. / normal[2]\nxx = xx + 50\nyy = yy + 50\nz = z + 50\n\nax.set_zlim((-20, 120)), ax.set_ylim((-20, 100)), ax.set_xlim((30, 75))\nax.plot_surface(xx, yy, z, alpha=.10)\n\nax = fig.add_subplot(122, projection='3d')\nax.azim=10\nax.elev=20\n#ax.dist=8\nax.scatter(dataThreeD[:,0], dataThreeD[:,1], dataThreeD[:,2], c=clrs, s=14**2)\n\nax.set_zlim((-20, 120)), ax.set_ylim((-20, 100)), ax.set_xlim((30, 75))\nax.plot_surface(xx, yy, z, alpha=.1)\nplt.tight_layout()\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["#### **(2c) 3D to 2D**\n#### We will now use PCA to see if we can recover the 2-dimensional plane on which the data live. Parallelize the data, and use our PCA function from above, with k=2 components."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["threeDData = sc.parallelize(dataThreeD)\ncomponentsThreeD, threeDScores, eigenvaluesThreeD = pca(threeDData, 2)\n\nprint 'componentsThreeD: \\n{0}'.format(componentsThreeD)\nprint ('\\nthreeDScores (first three): \\n{0}'\n       .format('\\n'.join(map(str, threeDScores.take(3)))))\nprint '\\neigenvaluesThreeD: \\n{0}'.format(eigenvaluesThreeD)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["#### **Visualization 4: 2D representation of 3D data**\n#### See the 2D version of the data that captures most of its original structure.  Note that darker blues correspond to points with higher values for the original data's third dimension."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["scoresThreeD = np.asarray(threeDScores.collect())\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(20, 150, 20), np.arange(-40, 110, 20))\nax.set_xlabel(r'New $x_1$ values'), ax.set_ylabel(r'New $x_2$ values')\nax.set_xlim(5, 150), ax.set_ylim(-45, 50)\nplt.scatter(scoresThreeD[:,0], scoresThreeD[:,1], s=14**2, c=clrs, edgecolors='#8cbfd0', alpha=0.75)\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["#### **(2d) Variance explained**\n#### Finally, let's quantify how much of the variance is being captured by PCA in each of the three synthetic datasets we've analyzed.  To do this, we'll compute the fraction of retained variance by the top principal components."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def varianceExplained(data, k=1):\n    \"\"\"Calculate the fraction of variance explained by the top `k` eigenvectors.\n\n    Args:\n        data (RDD of np.ndarray): An RDD that contains NumPy arrays which store the\n            features for an observation.\n        k: The number of principal components to consider.\n\n    Returns:\n        float: A number between 0 and 1 representing the percentage of variance explained\n            by the top `k` eigenvectors.\n    \"\"\"\n    components, scores, eigenvalues = pca(data, k)\n    return eigenvalues[0:k].sum()/eigenvalues.sum()\n\nvarianceRandom1 = varianceExplained(randomData, 1)\nvarianceCorrelated1 = varianceExplained(correlatedData, 1)\nvarianceRandom2 = varianceExplained(randomData, 2)\nvarianceCorrelated2 = varianceExplained(correlatedData, 2)\nvarianceThreeD2 = varianceExplained(threeDData, 2)\nprint ('Percentage of variance explained by the first component of randomData: {0:.1f}%'\n       .format(varianceRandom1 * 100))\nprint ('Percentage of variance explained by both components of randomData: {0:.1f}%'\n       .format(varianceRandom2 * 100))\nprint ('\\nPercentage of variance explained by the first component of correlatedData: {0:.1f}%'.\n       format(varianceCorrelated1 * 100))\nprint ('Percentage of variance explained by both components of correlatedData: {0:.1f}%'\n       .format(varianceCorrelated2 * 100))\nprint ('\\nPercentage of variance explained by the first two components of threeDData: {0:.1f}%'\n       .format(varianceThreeD2 * 100))"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["### **Part 3:  Parse, inspect, and preprocess neuroscience data then perform PCA **"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["#### **Data introduction**\n#### A central challenge in neuroscience is understanding the organization and function of neurons, the cells responsible for processing and representing information in the brain. New technologies make it possible to monitor the responses of large populations of neurons in awake animals. In general, neurons communicate through electrical impulses that must be recorded with electrodes, which is a challenging process. As an alternative, we can genetically engineer animals so that their neurons express special proteins that flouresce or light up when active, and then use microscopy to record neural activity as images. A recently developed method called light-sheet microscopy lets us do this in a special, transparent animal, the larval zebrafish, over nearly its entire brain. The resulting data are time-varying images containing the activity of hundreds of thousands of neurons. Given the raw data, which is enormous, we want to find compact spatial and temporal patterns: Which groups of neurons are active together? What is the time course of their activity? Are those patterns specific to particular events happening during the experiment (e.g. a stimulus that we might present). PCA is a powerful technique for finding spatial and temporal patterns in these kinds of data, and that's what we'll explore here!"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["#### **(3a) Load neuroscience data**\n#### In the next sections we will use PCA to capture structure in neural datasets. Before doing the analysis, we will load and do some basic inspection of the data. The raw data are currently stored as a text file. Every line in the file contains the time series of image intensity for a single pixel in a time-varying image (i.e. a movie). The first two numbers in each line are the spatial coordinates of the pixel, and the remaining numbers are the time series. We'll use first() to inspect a single row, and print just the first 100 characters."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["import os\nimport sys\nimport os.path\nimport pyspark\n\nnumPartitions = 2\nlines = sc.textFile('databricks-datasets/cs190/data-001/neuro.txt', numPartitions)\nprint lines.first()[0:100]\n\n# Check that everything loaded properly\nassert len(lines.first()) == 1397\nassert lines.count() == 46460"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["#### **(3b) Parse the data**\n#### Parse the data into a key-value representation. We want each key to be a tuple of two-dimensional spatial coordinates and each value to be a NumPy array storing the associated time series."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def parse(line):\n    \"\"\"Parse the raw data into a (`tuple`, `np.ndarray`) pair.\n\n    Note:\n        You should store the pixel coordinates as a tuple of two ints and the elements of the pixel intensity\n        time series as an np.ndarray of floats.\n\n    Args:\n        line (str): A string representing an observation.  Elements are separated by spaces.  The\n            first two elements represent the coordinates of the pixel, and the rest of the elements\n            represent the pixel intensity over time.\n\n    Returns:\n        tuple of tuple, np.ndarray: A (coordinate, pixel intensity array) `tuple` where coordinate is\n            a `tuple` containing two values and the pixel intensity is stored in an NumPy array\n            which contains 240 values.\n    \"\"\"\n    \n    data_list = line.split(\" \")\n    coord = (int(data_list[0]),int(data_list[1]))\n    intensity = np.asarray(data_list[2:],dtype=float)\n    return (coord,intensity)\n  \nrawData = lines.map(parse)\nrawData.cache()\nentry = rawData.first()\nprint 'Length of movie is {0} seconds'.format(len(entry[1]))\nprint 'Number of pixels in movie is {0:,}'.format(rawData.count())\nprint ('\\nFirst entry of rawData (with only the first five values of the NumPy array):\\n({0}, {1})'\n       .format(entry[0], entry[1][:5]))"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["#### **(3c) Min and max flouresence**\n#### Next we'll do some basic preprocessing on the data. The raw time-series data are in units of image flouresence, and baseline flouresence varies somewhat arbitrarily from pixel to pixel."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["mn = rawData.map(lambda (k, v): v).map(lambda v: min(v)).min()\nmx = rawData.map(lambda (k, v): v).map(lambda v: max(v)).max()\n\nprint mn, mx"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["#### **Visualization 5: Pixel intensity**\n#### Let's now see how a random pixel varies in value over the course of the time series.  We'll visualize a pixel that exhibits a standard deviation of over 100."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["example = rawData.filter(lambda (k, v): np.std(v) > 100).values().first()\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(0, 300, 50), np.arange(300, 800, 100))\nax.set_xlabel(r'time'), ax.set_ylabel(r'flouresence')\nax.set_xlim(-20, 270), ax.set_ylim(270, 730)\nplt.plot(range(len(example)), example, c='#8cbfd0', linewidth='3.0')\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["#### **(3d) Fractional signal change**"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def rescale(ts):\n    \"\"\"Take a np.ndarray and return the standardized array by subtracting and dividing by the mean.\n\n    Note:\n        You should first subtract the mean and then divide by the mean.\n\n    Args:\n        ts (np.ndarray): Time series data (`np.float`) representing pixel intensity.\n\n    Returns:\n        np.ndarray: The times series adjusted by subtracting the mean and dividing by the mean.\n    \"\"\"\n    mean = ts.mean()\n    return (ts - mean)/mean\n\nscaledData = rawData.mapValues(lambda v: rescale(v))\nmnScaled = scaledData.map(lambda (k, v): v).map(lambda v: min(v)).min()\nmxScaled = scaledData.map(lambda (k, v): v).map(lambda v: max(v)).max()\nprint mnScaled, mxScaled"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["#### **Visualization 6: Normalized data**\n#### Now that we've normalized our data, let's once again see how a random pixel varies in value over the course of the time series.  We'll visualize a pixel that exhibits a standard deviation of over 0.1.  Note the change in scale on the y-axis compared to the previous visualization."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["example = scaledData.filter(lambda (k, v): np.std(v) > 0.1).values().first()\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(0, 300, 50), np.arange(-.1, .6, .1))\nax.set_xlabel(r'time'), ax.set_ylabel(r'flouresence')\nax.set_xlim(-20, 260), ax.set_ylim(-.12, .52)\nplt.plot(range(len(example)), example, c='#8cbfd0', linewidth='3.0')\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["#### **(3e) PCA on the scaled data**\n#### We now have a preprocessed dataset with n = 46460 pixels and d = 240 seconds of time series data for each pixel.  We can interpret the pixels as our observations and each pixel value in the time series as a feature.  We would like to find patterns in brain activity during this time series, and we expect to find correlations over time.  We can thus use PCA to find a more compact representation of our data and allow us to visualize it."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["# Run pca using scaledData\ncomponentsScaled, scaledScores, eigenvaluesScaled = pca(scaledData.map(lambda (k, v): v),3)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["#### **Visualization 7: Top two components as images**\n#### Now, we'll view the scores for the top two component as images.  Note that we reshape the vectors by the dimensions of the original image, 230 x 202.\n#### These graphs map the values for the single component to a grayscale image.  This provides us with a visual representation which we can use to see the overall structure of the zebrafish brain and to identify where high and low values occur.  However, using this representation, there is a substantial amount of useful information that is difficult to interpret.  In the next visualization, we'll see how we can improve interpretability by combining the two principal components into a single image using a color mapping."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["import matplotlib.cm as cm\n\nscoresScaled = np.vstack(scaledScores.collect())\nimageOneScaled = scoresScaled[:,0].reshape(230, 202).T\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(0, 10, 1), np.arange(0, 10, 1), figsize=(9.0, 7.2), hideLabels=True)\nax.grid(False)\nax.set_title('Top Principal Component', color='#888888')\nimage = plt.imshow(imageOneScaled,interpolation='nearest', aspect='auto', cmap=cm.gray)\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":["imageTwoScaled = scoresScaled[:,1].reshape(230, 202).T\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(0, 10, 1), np.arange(0, 10, 1), figsize=(9.0, 7.2), hideLabels=True)\nax.grid(False)\nax.set_title('Second Principal Component', color='#888888')\nimage = plt.imshow(imageTwoScaled,interpolation='nearest', aspect='auto', cmap=cm.gray)\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":["#### **Visualization 8: Top two components as one image**\n#### When we perform PCA and color neurons based on their location in the low-dimensional space, we can interpret areas with similar colors as exhibiting similar responses (at least in terms of the simple representation we recover with PCA). Below, the first graph shows how low-dimensional representations, which correspond to the first two principal components, are mapped to colors. The second graph shows the result of this color mapping using the zebrafish neural data.\n \n####The second graph clearly exhibits patterns of neural similarity throughout different regions of the brain.  However, when performing PCA on the full dataset, there are multiple reasons why neurons might have similar responses. The neurons might respond similarly to different stimulus directions, their responses might have  similar temporal dynamics, or their response similarity could be influenced by both temporal and stimulus-specific factors. However, with our initial PCA analysis, we cannot pin down the underlying factors, and hence it is hard to interpret what \"similarity\" really means."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def polarTransform(scale, img):\n    \"\"\"Convert points from cartesian to polar coordinates and map to colors.\"\"\"\n    from matplotlib.colors import hsv_to_rgb\n\n    img = np.asarray(img)\n    dims = img.shape\n\n    phi = ((np.arctan2(-img[0], -img[1]) + np.pi/2) % (np.pi*2)) / (2 * np.pi)\n    rho = np.sqrt(img[0]**2 + img[1]**2)\n    saturation = np.ones((dims[1], dims[2]))\n\n    out = hsv_to_rgb(np.dstack((phi, saturation, scale * rho)))\n\n    return np.clip(out * scale, 0, 1)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":54},{"cell_type":"code","source":["# Show the polar mapping from principal component coordinates to colors.\nx1AbsMax = np.max(np.abs(imageOneScaled))\nx2AbsMax = np.max(np.abs(imageTwoScaled))\n\nnumOfPixels = 300\nx1Vals = np.arange(-x1AbsMax, x1AbsMax, (2 * x1AbsMax) / numOfPixels)\nx2Vals = np.arange(x2AbsMax, -x2AbsMax, -(2 * x2AbsMax) / numOfPixels)\nx2Vals.shape = (numOfPixels, 1)\n\nx1Data = np.tile(x1Vals, (numOfPixels, 1))\nx2Data = np.tile(x2Vals, (1, numOfPixels))\n\n# Try changing the first parameter to lower values\npolarMap = polarTransform(2.0, [x1Data, x2Data])\n\ngridRange = np.arange(0, numOfPixels + 25, 25)\nfig, ax = preparePlot(gridRange, gridRange, figsize=(9.0, 7.2), hideLabels=True)\nimage = plt.imshow(polarMap, interpolation='nearest', aspect='auto')\nax.set_xlabel('Principal component one'), ax.set_ylabel('Principal component two')\ngridMarks = (2 * gridRange / float(numOfPixels) - 1.0)\nx1Marks = x1AbsMax * gridMarks\nx2Marks = -x2AbsMax * gridMarks\nax.get_xaxis().set_ticklabels(map(lambda x: '{0:.1f}'.format(x), x1Marks))\nax.get_yaxis().set_ticklabels(map(lambda x: '{0:.1f}'.format(x), x2Marks))\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":55},{"cell_type":"code","source":["# Use the same transformation on the image data\n# Try changing the first parameter to lower values\nbrainmap = polarTransform(2.0, [imageOneScaled, imageTwoScaled])\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(0, 10, 1), np.arange(0, 10, 1), figsize=(9.0, 7.2), hideLabels=True)\nax.grid(False)\nimage = plt.imshow(brainmap,interpolation='nearest', aspect='auto')\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":["### **Part 4: Feature-based aggregation and PCA**"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["#### **(4a) Aggregation using arrays**\n \n#### In the analysis in Part 3, we performed PCA on the full time series data, trying to find global patterns across all 240 seconds of the time series. However, our analysis doesn't use the fact that different events happened during those 240 seconds. Specifically, during those 240 seconds, the zebrafish was presented with 12 different direction-specific visual patterns, with each one lasting for 20 seconds, for a total of 12 x 20 = 240 features. Stronger patterns are likely to emerge if we incorporate knowledge of our experimental setup into our analysis.  As we'll see, we can isolate the impact of temporal response or direction-specific impact by appropriately aggregating our features."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["#### **(4b) Aggregate by time**, we would like to incorporate knowledge of our experimental setup into our analysis. To do this, we'll first study the temporal aspects of neural response, by aggregating our features by time. In other words, we want to see how different pixels (and the underlying neurons captured in these pixels) react in each of the 20 seconds after a new visual pattern is displayed, regardless of what the pattern is.  Hence, instead of working with the 240 features individually, we'll aggregate the original features into 20 new features, where the first new feature captures the pixel response one second after a visual pattern appears, the second new feature is the response after two seconds, and so on."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["# Create a multi-dimensional array to perform the aggregation\nT = np.tile(np.eye(20),12)\n\n# Transform scaledData using T.  Make sure to retain the keys.\ntimeData = scaledData.map(lambda (k, v): (k,T.dot(v)))\n\ntimeData.cache()\nprint timeData.count()\nprint timeData.first()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["#### **(4c) Obtain a compact representation**\n#### We now have a time-aggregated dataset with n = 46460 pixels and d = 20 aggregated time features, and we want to use PCA to find a more compact representation."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["componentsTime, timeScores, eigenvaluesTime = pca(timeData.map(lambda (k, v): v),3)\n\nprint 'componentsTime: (first five) \\n{0}'.format(componentsTime[:5,:])\nprint ('\\ntimeScores (first three): \\n{0}'\n       .format('\\n'.join(map(str, timeScores.take(3)))))\nprint '\\neigenvaluesTime: (first five) \\n{0}'.format(eigenvaluesTime[:5])"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":["#### ** Visualization 9: Top two components by time **\n#### Let's view the scores from the first two PCs as a composite image. When we preprocess by aggregating by time and then perform PCA, we are only looking at variability related to temporal dynamics. As a result, if neurons appear similar -- have similar colors -- in the resulting image, it means that their responses vary similarly over time, regardless of how they might be encoding direction. In the image below, we can define the midline as the horizontal line across the middle of the brain.  We see clear patterns of neural activity in different parts of the brain, and crucially note that the regions on either side of the midline are similar, which suggests that temporal dynamics do not differ across the two sides of the brain."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["scoresTime = np.vstack(timeScores.collect())\nimageOneTime = scoresTime[:,0].reshape(230, 202).T\nimageTwoTime = scoresTime[:,1].reshape(230, 202).T\nbrainmap = polarTransform(3, [imageOneTime, imageTwoTime])\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(0, 10, 1), np.arange(0, 10, 1), figsize=(9.0, 7.2), hideLabels=True)\nax.grid(False)\nimage = plt.imshow(brainmap,interpolation='nearest', aspect='auto')\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":64},{"cell_type":"markdown","source":["#### **(4d) Aggregate by direction**\n#### Next, let's perform a second type of feature aggregation so that we can study the direction-specific aspects of neural response, by aggregating our features by direction. In other words, we want to see how different pixels (and the underlying neurons captured in these pixels) react when the zebrafish is presented with 12 direction-specific patterns, ignoring the temporal aspect of the reaction.  Hence, instead of working with the 240 features individually, we'll aggregate the original features into 12 new features, where the first new feature captures the average pixel response to the first direction-specific visual pattern, the second new feature is the response to the second direction-specific visual pattern, and so on."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["# Create a multi-dimensional array to perform the aggregation\nD = np.kron(np.eye(12),np.ones(20))\n\n# Transform scaledData using D.  Make sure to retain the keys.\ndirectionData = scaledData.map(lambda (k, v): (k,D.dot(v)))\n\ndirectionData.cache()\nprint directionData.count()\nprint directionData.first()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":["#### **(4e) Compact representation of direction data**\n#### We now have a direction-aggregated dataset with n = 46460 pixels and d = 12 aggregated direction features, and we want to use PCA to find a more compact representation."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["componentsDirection, directionScores, eigenvaluesDirection = pca(directionData.map(lambda (k, v): v),3)\n\nprint 'componentsDirection: (first five) \\n{0}'.format(componentsDirection[:5,:])\nprint ('\\ndirectionScores (first three): \\n{0}'\n       .format('\\n'.join(map(str, directionScores.take(3)))))\nprint '\\neigenvaluesDirection: (first five) \\n{0}'.format(eigenvaluesDirection[:5])"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":["#### **Visualization 10: Top two components by direction**\n#### Again, let's view the scores from the first two PCs as a composite image.  When we preprocess by averaging across time (group by direction), and then perform PCA, we are only looking at variability related to stimulus direction. As a result, if neurons appear similar -- have similar colors -- in the image, it means that their responses vary similarly across directions, regardless of how they evolve over time. In the image below, we see a different pattern of similarity across regions of the brain.  Moreover, regions on either side of the midline are colored differently, which suggests that we are looking at a property, direction selectivity, that has a different representation across the two sides of the brain."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["scoresDirection = np.vstack(directionScores.collect())\nimageOneDirection = scoresDirection[:,0].reshape(230, 202).T\nimageTwoDirection = scoresDirection[:,1].reshape(230, 202).T\nbrainmap = polarTransform(2, [imageOneDirection, imageTwoDirection])\n# with thunder: Colorize(cmap='polar', scale=2).transform([imageOneDirection, imageTwoDirection])\n\n# generate layout and plot data\nfig, ax = preparePlot(np.arange(0, 10, 1), np.arange(0, 10, 1), figsize=(9.0, 7.2), hideLabels=True)\nax.grid(False)\nimage = plt.imshow(brainmap, interpolation='nearest', aspect='auto')\npass\n\ndisplay(fig)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":70},{"cell_type":"markdown","source":["#### **(4f) Next steps**\n#### In the analyses above we have successfully identified regions of the brain that encode particular properties, e.g., a particular temporal pattern or selectivity to a stimulus. However, this is only the first step! These exploratory analyses are typically followed with more targeted investigation, both through analysis and experiment. For example, we might find all neurons that prefer one stimulus direction, and then do an experiment in which we stimulate or inactivate only those neurons and look at the effect on the animal's behavior. Alternatively, we might subdivide neurons into groups based on simple forms of stimulus selectivity like the ones analyzed here, and then estimate coupling across different neuronal populations, i.e. can we predict one population's response as a function of another. This can  be framed as a massive pair-wise regression problem, related to techniques you learned earlier in the course, and demanding large-scale implementations."],"metadata":{"deletable":true,"editable":true}}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.10","nbconvert_exporter":"python","file_extension":".py"},"name":"hw4_pca_student","notebookId":1027605090603469},"nbformat":4,"nbformat_minor":0}
